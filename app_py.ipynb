{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muthumaha-S/Alzheimer_Prediction/blob/main/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0e1qmy3kkzK",
        "outputId": "3e47ee37-f875-4434-a50e-6ba8ee9e385b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "# Flask app initialization\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set upload folder\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# Ensure uploads folder exists\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "# Load the trained model\n",
        "MODEL_PATH = '/content/drive/MyDrive/alzheimers_prediction/alzheimer_prediction_model.h5'\n",
        "model = load_model(MODEL_PATH)\n",
        "\n",
        "# Categories should match the training labels\n",
        "CATEGORIES = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n",
        "\n",
        "IMG_SIZE = 128  # Must be the same size as used in training\n",
        "\n",
        "\n",
        "# Convert grayscale image to RGB (3 channels)\n",
        "def convert_to_rgb(image):\n",
        "    return np.repeat(image, 3, axis=-1)\n",
        "\n",
        "\n",
        "# Home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "# Prediction route\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "\n",
        "    if file:\n",
        "        filename = secure_filename(file.filename)\n",
        "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "        file.save(file_path)\n",
        "\n",
        "        # Process the image\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0  # Normalize\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension (128, 128, 1)\n",
        "        img = np.expand_dims(img, axis=0)   # Add batch dimension (1, 128, 128, 1)\n",
        "\n",
        "        # Convert to RGB (128, 128, 3)\n",
        "        img_rgb = convert_to_rgb(img)\n",
        "\n",
        "        # Make prediction\n",
        "        pred = model.predict(img_rgb)\n",
        "        class_idx = np.argmax(pred, axis=1)[0]\n",
        "        prediction = CATEGORIES[class_idx]\n",
        "\n",
        "        # Pass the file path and prediction to the result page\n",
        "        image_url = url_for('static', filename=f'uploads/{filename}')\n",
        "        # Save uploaded images in static/uploads folder if necessary\n",
        "        static_upload_path = os.path.join('static/uploads', filename)\n",
        "        os.makedirs(os.path.dirname(static_upload_path), exist_ok=True)\n",
        "        cv2.imwrite(static_upload_path, cv2.imread(file_path))\n",
        "\n",
        "        return render_template('result.html', prediction=prediction, image_url=image_url)\n",
        "\n",
        "    return redirect(url_for('home'))\n",
        "\n",
        "\n",
        "# Run the app\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1lwH-jt1RlGylyIJhQCnRK-HnrWRKL5ar",
      "authorship_tag": "ABX9TyM9P+hYLVjisPlxU7cYwCVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}