{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdcZmLEijlebK1sgIulhS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muthumaha-S/Alzheimer_Prediction/blob/main/Alzhiemer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5L9eLylwaT0"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/\"))"
      ],
      "metadata": {
        "id": "rjl1zqETw89e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "TfmBrA1exEPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "-SR0K68OxGcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cBS8Uj_zxN7C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB-S6oq8X0o1"
      },
      "source": [
        " Load and Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/archive/alziemer_dataset/\"  # Check if this exists\n",
        "\n",
        "# Check if the dataset path exists\n",
        "print(\"Dataset Directory Exists:\", os.path.exists(DATA_DIR))\n",
        "\n",
        "# If exists, list the contents\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(\"Dataset Structure:\", os.listdir(DATA_DIR))\n",
        "else:\n",
        "    print(\"Error: Dataset path is incorrect!\")"
      ],
      "metadata": {
        "id": "PKeVgR47xSb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/archive/alziemer_dataset/\"\n",
        "IMG_SIZE = 128  # Resize all images to 128x128\n",
        "BATCH_SIZE = 32  # Batch size for training"
      ],
      "metadata": {
        "id": "GJWYbiCmxXBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Exists:\", os.path.exists(DATASET_PATH))\n",
        "print(\"Dataset Structure:\", os.listdir(DATASET_PATH) if os.path.exists(DATASET_PATH) else \"Path not found\")\n",
        "\n",
        "# Check individual category folders\n",
        "for folder in [\"train\", \"test\", \"val\"]:\n",
        "    path = os.path.join(DATASET_PATH, folder)\n",
        "    print(f\"{folder.capitalize()} Categories:\", os.listdir(path) if os.path.exists(path) else \"Not Found\")"
      ],
      "metadata": {
        "id": "N8dafVDAxaFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ifF9BLEKxd8_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPTPxqMtYStD"
      },
      "source": [
        "Load Data Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "bYm-KIasxev7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define categories\n",
        "CATEGORIES = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n",
        "\n",
        "# Function to load images from dataset\n",
        "def load_data(directory):\n",
        "    images, labels = [], []\n",
        "\n",
        "    for label_idx, label in enumerate(CATEGORIES):\n",
        "        class_path = os.path.join(directory, label)\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "                # Ensure the file is an image\n",
        "                if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    continue\n",
        "\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Skipping unreadable image: {img_path}\")\n",
        "                    continue  # Skip unreadable images\n",
        "\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0  # Normalize\n",
        "                images.append(img)\n",
        "                labels.append(label_idx)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    images = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # Add channel dimension\n",
        "    labels = to_categorical(labels, num_classes=len(CATEGORIES))\n",
        "\n",
        "    return images.astype('float32'), labels\n",
        "\n",
        "# Load training, validation, and test data\n",
        "X_train, y_train = load_data(os.path.join(DATASET_PATH, \"train\"))\n",
        "X_val, y_val = load_data(os.path.join(DATASET_PATH, \"val\"))\n",
        "X_test, y_test = load_data(os.path.join(DATASET_PATH, \"test\"))\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"✅ Train set: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"✅ Validation set: {X_val.shape}, Labels: {y_val.shape}\")\n",
        "print(f\"✅ Test set: {X_test.shape}, Labels: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "AzPyb2i8xiJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "def build_unet_model():\n",
        "    inputs = Input((IMG_SIZE, IMG_SIZE, 1))  # Grayscale MRI images , 1 channel because these are grayscale MRI scans.\n",
        "\n",
        "    # Encoder (Downsampling)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "\n",
        "    # Decoder (Upsampling)\n",
        "    u1 = UpSampling2D((2, 2))(c3)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2))(c4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)  # Binary segmentation mask\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "unet_model = build_unet_model()\n",
        "unet_model.summary()"
      ],
      "metadata": {
        "id": "HmVmj6ZayO4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_segmentation(index):\n",
        "    # Get original image\n",
        "    original = X_test[index].squeeze()\n",
        "\n",
        "    # Predict segmentation mask\n",
        "    predicted_mask = unet_model.predict(X_test[index].reshape(1, IMG_SIZE, IMG_SIZE, 1)).squeeze()\n",
        "\n",
        "    # Threshold the predicted mask to make it binary\n",
        "    binary_mask = (predicted_mask > 0.5).astype('float32')\n",
        "\n",
        "    # Plot original and segmented mask side by side\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original, cmap='gray')\n",
        "    plt.title(\"Original MRI\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(binary_mask, cmap='gray')\n",
        "    plt.title(\"Segmented Brain Mask\")\n",
        "\n",
        "    # Overlay segmentation on original for better visualization\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(original, cmap='gray')\n",
        "    plt.imshow(binary_mask, cmap='jet', alpha=0.5)  # Overlay with transparency\n",
        "    plt.title(\"Overlay (Segmentation + MRI)\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_segmentation(10)\n",
        "\n",
        "#  Define a function to convert grayscale images to RGB format\n",
        "def convert_to_rgb(dataset):\n",
        "    return np.repeat(dataset, 3, axis=-1)  # Convert (128, 128, 1) → (128, 128, 3) # Function takes a dataset (4D array: samples, height, width, channels)\n",
        "\n",
        "X_train_rgb = convert_to_rgb(X_train)\n",
        "X_val_rgb = convert_to_rgb(X_val)\n",
        "X_test_rgb = convert_to_rgb(X_test)\n",
        "\n",
        "print(f\"✅ RGB Training Data Shape: {X_train_rgb.shape}\")"
      ],
      "metadata": {
        "id": "ZEnGVSJL5Xkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"
      ],
      "metadata": {
        "id": "9cKvVdE55oN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define ResNet-101 Model\n",
        "base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze all ResNet layers Freezing prevents overfitting\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add Custom Layers for Classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # ✅ Fix applied here\n",
        "x = Dense(512, activation='relu')(x) #Adds a fully connected (dense) layer with 512 neurons.\n",
        "x = Dropout(0.5)(x) #Adds Dropout regularization with a dropout rate of 50%.   Prevents overfitting by forcing the network to learn redundant, robust features.\n",
        "output_layer = Dense(len(CATEGORIES), activation='softmax')(x)\n",
        "\n",
        "# Create Final Model\n",
        "resnet_model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile Model\n",
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print Model Summary\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "lsatz2SL-YmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet = resnet_model.fit(\n",
        "    X_train_rgb, y_train,\n",
        "    validation_data=(X_val_rgb, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "YADuxkUYHKr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZATION REPORT"
      ],
      "metadata": {
        "id": "2ELCQ6emP_Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(resnet_model.predict(X_test_rgb), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=CATEGORIES))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
        "plt.title('Confusion Matrix - ResNet101')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vXSl3FB9HPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar Plot of Predictions per Category\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Bar plot of predictions per category\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=[CATEGORIES[i] for i in y_pred], order=CATEGORIES, palette=\"Set2\")\n",
        "plt.title(\"Predicted Distribution of Classes\")\n",
        "plt.xlabel(\"Dementia Category\")\n",
        "plt.ylabel(\"Number of Predictions\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1E4bcEWuQHNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training & Validation Accuracy and Loss Curves\n",
        "\n",
        "# Accuracy plot\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_resnet.history['accuracy'], label='Train Accuracy', marker='o')\n",
        "plt.plot(history_resnet.history['val_accuracy'], label='Val Accuracy', marker='o')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_resnet.history['loss'], label='Train Loss', marker='o')\n",
        "plt.plot(history_resnet.history['val_loss'], label='Val Loss', marker='o')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m6dHdLkeQbXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)  # Convert to (128, 128, 1)\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    img_rgb = convert_to_rgb(img)  # Convert to (128, 128, 3) for ResNet\n",
        "\n",
        "    pred = np.argmax(resnet_model.predict(img_rgb), axis=1)[0]\n",
        "    print(f\"Prediction: {CATEGORIES[pred]}\")\n",
        "\n",
        "predict_image(\"/content/drive/MyDrive/ig.jpg\")\n"
      ],
      "metadata": {
        "id": "CJnOJzUYHS8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.save('/content/drive/MyDrive/alzheimers_prediction/alzheimer_prediction_model.h5')\n"
      ],
      "metadata": {
        "id": "VQvQw19YHXHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}